---
output: html_document
runtime: shiny
---

```{=html}
<link href="https://fonts.googleapis.com/css2?family=Source+Sans+Pro&display=swap" rel="stylesheet">
<style type="text/css">
.main-container {
  max-width: 750px;
  margin-left: auto;
  margin-right: auto;
}
  body {
    font-family: 'Source Sans Pro', sans-serif;
    font-size: 1.75em; /* Slightly bigger than default (1em) */
  }
</style>
```

```{css, echo=FALSE}
.plotlysize {
  height: 220px;
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(plotly)
library(purrr)
library(shiny)
library(splines)
library(tidyverse)
library(shiny.blueprint)
options(shiny.plot.res=96)
```

This document helps visualize the various steps occurring in an infectious disease outbreak.

```{r pressure, echo=FALSE, fig.cap="Figure 1 from Lehtinen et. al. (2021)", out.width = '60%'}
knitr::include_graphics("img/Lehtinen_fig1.jpg")
```

For this simulation, we take several steps to simulate how cases spread from one person to another: 

1. First, we simulate the **incubation time** distribution, $I_i$, the time between between infection and sympton onset (/when one person can infect another)
2. Next, we simulate the **transmission time** distribution, $P_{ij}$. This is the defined as the time between symptom onset in one person and infection in another. When transmission time and incubation time are assumed to be independent, the generation interval $G_{ij}$ (the time between infections), and the serial interval, $S_{ij}$ (the time between disease onsets) are equivalent.
3. Third, we simulate the the individual-level **administrative delay** in reporting, the time between **symptom onset** and **case reporting** to a public health agency (not shown above).
4. Finally, we simulate the population-level infectivity dynamics, i.e., $R(t)$ (not shown above).

With all of these factors together, we can see how a disease outbreak gets reported to administrative databases that then can be used to calculate $R(t)$ that informs public health decision making.

```{r seed_set, echo = F,include=F}
inputPanel(shiny::helpText("set.seed(123)"))
set.seed(123)
```


<div style="border: 2px dotted black; border-radius: 15px;padding: 5px; background-color: lightyellow;">
<h3 style="margin-top: 5px; font-size: 1.25em;">How to read the distribution graphs below</h3>

In each of the distribution graphs below, the y-axis says P(x). This is the probability of an individual having a incubation time (or other distribution) on that specific day. So the most number of people will have a incubation time where P(x) is the highest
</div>


### Incubation time distribution
Incubation time is defined as the time between **infection** and **symptom onset** for an individual. We used a minimum incubation time (1 day) and a maximum incubation time (user defined). The "spread" of the distribution is controlled by the "size" parameter. The Incubation of exactly 1 day can be achieved by setting Size = 1e-10. 

```{r inc_interval, echo=FALSE}
INC_MIN = 1

## INPUTS
inputPanel(
  # row 1
  sliderInput("inc_i_mean", label = "Mean (days)", value = 2, min = 1, max = 15),
  sliderInput("inc_i_size", label = "Size", pre = '1e', value = 2, min = -10, max = 10),
  sliderInput("maxinc", label = "Max. incubation time (days)", value = 11,
              min = 5, max = 15, step = 1)
)

inc_data <- reactive({
  data.frame(x = sample(0:input$maxinc, 
                          size = 5000, 
                          prob = dnbinom(0:input$maxinc, 
                                         size = 1*10^input$inc_i_size, 
                                         mu = input$inc_i_mean), 
                          replace = TRUE) + INC_MIN ) %>%
      group_by(x) %>% tally() %>%
    mutate(n = n / sum(n)) 
})

inc_max <- reactive({ max(as_tibble(inc_data())$n) })
```

```{r plot1, echo=F, out.width="100%"}
renderPlot({
    as_tibble(inc_data()) %>%
    ggplot(.,aes(x = x, y = n)) +
      geom_col(fill = 'white', color = 'black',
           width = 0.4) +
  geom_density(stat = 'identity', fill = '#FF6666', alpha = 0.2) +
    # geom_density(data = data.frame(x = rpois(5000, input$inc_i_mean)) %>%
    #                group_by(x) %>% tally() %>% mutate(n = n / sum(n)) ,
    #              aes(x = x + INC_MIN, y= n),
    #              stat = 'identity', fill = NA, color = 'blue', alpha = 0.2) +
    coord_cartesian(xlim = c(0, 15), ylim = c(0, as_vector(inc_max()))) +
    scale_x_continuous(minor_breaks = 1:15) +
    xlab('Days') + ylab('P(x)') +
    theme(
      axis.text = element_text(size = 10),
          axis.title = element_text(size = 14)
    )
}, height = 200)

```

### Transmission time distribution
Transmission time is defined as the time beteween between **symptom onset** in **infector** and **infection** in **infectee** for an individual. In this simulation we assume that the transmission time distribution is **independent** from the incubation time distribution. The "spread" of the distribution is controlled by the "size" parameter. Transmission of exactly 0 days can be achieved by setting Mean = 0, or Size = 1e-10. 

```{r trans_interval, echo=FALSE}
TRANS_MIN = 0

## INPUTS
inputPanel(
  # row 1
  sliderInput("trans_i_mean", label = "Mean (days)", value = 1, min = 0, max = 15),
  sliderInput("trans_i_size", label = "Size", pre = '1e', value = 2, min = -10, max = 10),
  sliderInput("maxtrans", label = "Max. transmission time (days)", value = 10,
              min = 5, max = 15, step = 1),
)

trans_data <- reactive({
      data.frame(x = sample(0:input$maxtrans, 
                          size = 5000, 
                          prob = dnbinom(0:input$maxtrans, 
                                         size = 1*10^input$trans_i_size, 
                                         mu = input$trans_i_mean), 
                          replace = TRUE) + TRANS_MIN ) %>%
      group_by(x) %>% tally() %>%
    mutate(n = n / sum(n)) 
})

trans_max <- reactive({ max(as_tibble(trans_data())$n) })

renderPlot({
    as_tibble(trans_data()) %>%
    ggplot() +
      geom_col(aes(x = x, y = n), fill = 'white', color = 'black',
           width = 0.4) +
  geom_density(aes(x = x, y = n), stat = 'identity', fill = '#FF6666', alpha = 0.2) +
        # geom_density(data = data.frame(x = rpois(5000, input$trans_i_mean)) %>%
        #            group_by(x) %>% tally() %>% mutate(n = n / sum(n)) ,
        #          aes(x = x + TRANS_MIN, y= n),
        #          stat = 'identity', fill = NA, color = 'blue', alpha = 0.2) +
    coord_cartesian(xlim = c(0, 15), ylim = c(0, as_vector(trans_max()))) +
    scale_x_continuous(minor_breaks = 1:15) +
    xlab('Days') + ylab('P(x)') +
    theme(
      axis.text = element_text(size = 10),
          axis.title = element_text(size = 14)
    )
}, height = 200)

```


### Generation time distribution
Generation time is the time between **infection** in the **infector** and **infection** in the **infectee**, dervied as $G_{ij} = I_{i} + P_{ij}$ (Eq. 2.1b from [Lehtinen et. al. (2021)](https://royalsocietypublishing.org/doi/10.1098/rsif.2020.0756)). Changes above to the incubation time or transmission time will affect this distribution. In this simulation we assume that the transmission time distribution is **independent** from the incubation time distribution, so the generation time distribution and serial interval distribution (below) are the same.

```{r gen_interval, echo=FALSE}

gen_data <- reactive({
      data.frame(x1 = sample(0:input$maxinc, 
                          size = 5000, 
                          prob = dnbinom(0:input$maxinc, 
                                         size = 1*10^input$inc_i_size, 
                                         mu = input$inc_i_mean), 
                          replace = TRUE) + INC_MIN,
               x2 = sample(0:input$maxtrans, 
                          size = 5000, 
                          prob = dnbinom(0:input$maxtrans, 
                                         size = 1*10^input$trans_i_size, 
                                         mu = input$trans_i_mean), 
                          replace = TRUE) + TRANS_MIN)     %>%
    mutate(x = x1 + x2) %>%
      group_by(x) %>% tally() %>%
    mutate(n = n / sum(n)) 
})

gen_max <- reactive({ max(as_tibble(gen_data())$n) })

renderPlot({
    as_tibble(gen_data()) %>%
    ggplot() +
      geom_col(aes(x = x, y = n), fill = 'white', color = 'black',
           width = 0.4) +
  geom_density(aes(x = x, y = n), stat = 'identity', fill = '#FF6666', alpha = 0.2) +
    coord_cartesian(xlim = c(0, 15), ylim = c(0, as_vector(gen_max()))) +
    scale_x_continuous(minor_breaks = 1:15) +
    xlab('Days') + ylab('P(x)') +
    theme(
      axis.text = element_text(size = 10),
          axis.title = element_text(size = 14)
    )
}, height = 200)

```


### Serial interval distribution
The serial interval is derived from the generation time distribution and the incubation time distribution: $S_{ij} = P_{ij} + I_j$ (Eq. 2.1a from [Lehtinen et. al. (2021)](https://royalsocietypublishing.org/doi/10.1098/rsif.2020.0756)). Changes above to the incubation time or transmission time will affect this distribution. In this simulation we assume that the transmission time distribution is **independent** from the incubation time distribution, so the serial interval distribution and generation time distribution (above) are the same.

```{r serial_interval, echo=FALSE}

serial_data <- reactive({
      data.frame(x1 = sample(0:input$maxinc, 
                          size = 5000, 
                          prob = dnbinom(0:input$maxinc, 
                                         size = 1*10^input$inc_i_size, 
                                         mu = input$inc_i_mean), 
                          replace = TRUE) + INC_MIN,
               x2 = sample(0:input$maxtrans, 
                          size = 5000, 
                          prob = dnbinom(0:input$maxtrans, 
                                         size = 1*10^input$trans_i_size, 
                                         mu = input$trans_i_mean), 
                          replace = TRUE) + TRANS_MIN)     %>%
    mutate(x = x1 + x2) %>%
      group_by(x) %>% tally() %>%
    mutate(n = n / sum(n))
})

serial_max <- reactive({ max(as_tibble(serial_data())$n) })

renderPlot({
    as_tibble(serial_data()) %>%
    ggplot() +
      geom_col(aes(x = x, y = n), fill = 'white', color = 'black',
           width = 0.4) +
  geom_density(aes(x = x, y = n), stat = 'identity', fill = '#FF6666', alpha = 0.2) +
    coord_cartesian(xlim = c(0, 15), ylim = c(0, as_vector(serial_max()))) +
    scale_x_continuous(minor_breaks = 1:15) +
    xlab('Days') + ylab('P(x)') +
    theme(
      axis.text = element_text(size = 10),
          axis.title = element_text(size = 14)
    )
}, height = 200)

```


### Reporting delay distribution
Finally, we model a reporting delay distribution, the time between **symptom onset** and **case reporting** to a public health agency. **In real-world settings this is likely two separate distributions**: one for how long it takes someone to get a positive test once their symptoms show, and the other for how long that positive test takes to be recorded in an administrative dataset. For the purpose of demonstration, we lump these together. Perfect (i.e., instantaneous) reporting can be modeled with NB mean of 0. 

```{r, echo=FALSE}
## INPUTS
inputPanel(
  # row 1
  sliderInput("NB_m", label = "Mean (days)", value = 5, min = 0., max = 20),
  sliderInput("NB_r", label = "Size", pre = '1e', value = 2, min = -1, max = 20),
  sliderInput("maxdelay", label = "Max. reporting delay (days)", value = 11,
              min = 10, max = 15, step = 1),
)

reporting_dist <- reactive({
      data.frame(x = sample(0:input$maxdelay, 
                          size = 5000, 
                          prob = dnbinom(0:input$maxdelay, 
                                         size = 1*10^input$NB_r, 
                                         mu = input$NB_m), 
                          replace = TRUE) ) %>%
      group_by(x) %>% tally() %>%
    mutate(n = n / sum(n))
})

reporting_max <- reactive({ max(as_tibble(reporting_dist())$n) })

renderPlot({
    as_tibble(reporting_dist()) %>%
    ggplot() +
      geom_col(aes(x = x, y = n), fill = 'white', color = 'black',
           width = 0.4) +
  geom_density(aes(x = x, y = n), stat = 'identity', fill = '#FF6666', alpha = 0.2) +
    coord_cartesian(xlim = c(0, 15), ylim = c(0, as_vector(reporting_max()))) +
    scale_x_continuous(minor_breaks = 1:15) +
    xlab('Days') + ylab('P(x)') +
    theme(
      axis.text = element_text(size = 10),
          axis.title = element_text(size = 14)
    )
}, height = 200)

```
### R(t) simulation

We first describe the daily infections, onsets, and reporting days of the first generation, i.e. the first round of infectees in the data. For example, this could be people that were exposed at a conference out of state that then traveled home and are now reporting in their home state. The number of initial cases (infectors) is set below, and the distributions defined above. Take a minute here to look at the graph below and compare to your distributions for incubation and transmission (and reporting delay, if you included that) - do they make sense?

```{r get_curves2, echo=FALSE}

plot_dat <- reactive({
  # ----------
  # one draw from poisson given by lambda = initial cases * initial reproductive number
  # this gives the first timestep of infectees from the initial cases
  # n1 <- rpois(1, 10^input$n0 * input$r0) 
  
  # so first is the date of infection, 
  # which is a draw from the transmission distribution
  # NOTE: WHY
  i1 = sample(0:input$maxtrans, 
                        size = 10^input$n0, 
                        prob = dnbinom(0:input$maxtrans, 
                                       size = 1*10^input$trans_i_size, 
                                       mu = input$trans_i_mean), 
                        replace = TRUE) + TRANS_MIN
  

  # next is onset times, which is transmission + incubation
  o1 = sample(0:input$maxinc, 
                          size = 10^input$n0, 
                          prob = dnbinom(0:input$maxinc, 
                                         size = 1*10^input$inc_i_size, 
                                         mu = input$inc_i_mean), 
                          replace = TRUE) + INC_MIN
  o1 = o1 + i1

  # Finally, reporting, which is transmission + incubation + reporting delay
  d1 = sample(0:input$maxdelay, 
                          size = 10^input$n0, 
                          prob = dnbinom(0:input$maxdelay, 
                                         size = 1*10^input$NB_r, 
                                         mu = input$NB_m), 
                          replace = TRUE)
  d1 <- o1 + d1

  # in addition, make a new draw for the generation interval with the 
  # reference person as the infectee
  # so this it the generation interval for EVERY J that EACH I infects.
  ## which is o1 + a new transmission draw for the next person
  ## this just gets the distribution of dates and then the r(t) is applied 
  ## to the sum to scale up the counts
  gi1 <- data.frame(x1 = o1,
               x2 = sample(0:input$maxtrans, 
                          size = 10^input$n0, 
                          prob = dnbinom(0:input$maxtrans, 
                                         size = 1*10^input$trans_i_size, 
                                         mu = input$trans_i_mean), 
                          replace = TRUE) + TRANS_MIN) %>%
    mutate(x = x1 + x2)
  
  # right and these all happen AFTER onset
  gi1 <- unname(gi1$x)
  
  # add generation #
  gen_i <- 1
  gen_i_c <- rep(gen_i, length(i1))
  
  # create a combined dataset
  dat <- cbind(i1, o1, d1, gi1, gen_i_c)
  
  dat
})
# 
# # Curves
# # area under the curve should be = 196
renderPlot({
  as_tibble(plot_dat()) %>%
    select(-gi1) %>%
    rename("Daily Infections" = i1,
           "Daily Onsets" = o1,
           "Daily Reports" = d1) %>%
    pivot_longer(cols = c("Daily Infections", "Daily Onsets",
                          "Daily Reports")) %>%
    group_by(name, gen_i_c, value) %>% tally() %>%
    ggplot(.) +
    geom_bar(aes(x = value, fill = factor(gen_i_c), y = n),
             position = 'stack', stat = 'identity', color = 'black',
             lwd = 0.1, fill = '#6495ED') +
    facet_wrap(~name, nrow = 1) +
    ylab('N') + xlab('Day') +
    scale_fill_brewer(name = 'Gen.#', type = 'seq',
                      direction = 1, palette = 3) +
    theme_gray() + 
    #coord_cartesian(xlim = c(0, 30), ylim = c(0, 50)) +
    theme(
      axis.text = element_text(size = 10),
          axis.title = element_text(size = 14),
          strip.text = element_text(size = 14)
    ) 
}, height = 200)
```

Now, create your $R(t)$ curve so you can simulate the next generation(s) of cases. Pre-defining the shape of $R(t)$ allows you to simulate infectious disease dynamics, interventions, etc. 


```{r bsdeg, echo=FALSE}
RTINF = 1

  div(
    style = "background-color: #f9f9f9; padding: 20px; border: 0.5px solid #ccc; 
             border-radius: 2px; 
             margin-bottom: 20px;",
  splitLayout(cellWidths = c('18%', '22%', '18%', '18%', '24%'),
  sliderInput("n0", label = "Initial cases:", width = '90%',
              pre = '1e',min = 1, max = 3, value = 3, step = 1),
  sliderInput("ld", label = "Model time (days):", value = 60,min = 20, 
              max = 100, step = 20, width = '90%'),
  sliderInput('BSDEG', 'Spline Degree:', value = 1, width = '90%',
              min = 1, max = 4, step = 1),
  radioButtons('GenType', 'Offspring dist:', choices = c('Poisson', 'NegBinom')),
  conditionalPanel(condition = "input.GenType == 'NegBinom'", 
                     sliderInput("NB_off", label = "NB size", pre = '1e', width = '90%',
              value = 10, min = 1, max = 10))
  ) #split
) #div

```

<div class = 'plotlysize'>
```{r set_rt, echo=FALSE}
# PLOT PARAMETERS
YMAX <- 2
NPTS <- 8
XSTART <- 1

# REFERENCE: # https://stackoverflow.com/questions/47280032/draggable-line-chart-in-r-shiny
### asb should be '30'
rv <- reactiveValues(
  x = NULL,
  #y = rep(1, length.out = NPTS)
  y = c(1.1, 1.5, 1.1, 0.5, 1, 1.5, 1, 1)
)

## these are the spline knots
observeEvent(input$ld, {
  rv$x <- seq(XSTART, input$ld, length.out = NPTS)
  #rv$y <- rep(1, times = NPTS)
})

## make sure that the output are on the day
## so this is a two-step process. first you make the linear data
## then you predict the spline based on BSDEG
rt_grid <- reactive({
  this.x <- seq(XSTART, input$ld, by = 1)
  suppressWarnings(this.y <- predict(linear.model(), data.frame(x = this.x)))
  linear_data = data.frame(x = this.x, y = this.y)
  X_mat <- bs(x = this.x, knots = rv$x, degree = input$BSDEG)
  m2 <- lm(this.y ~ X_mat)
  yspline <- predict(m2)
  data.frame(x = this.x, y = as.vector(yspline))
})

linear.model <- reactive({
  d <- data.frame(x = rv$x, y = rv$y)
  lm(y ~ bs(x, degree = 1, knots = rv$x), d)
})

# Render plot
renderPlotly({
  
  req(rv$x)
  req(rv$y)
  req(rt_grid()$x)
  req(rt_grid()$y)
  
  # creates a list of circle shapes from x/y data
  circles <- map2(
    rv$x, rv$y,
    ~ list(
      type = "circle",
      # anchor circles
      xanchor = .x,
      yanchor = .y,
      # give each circle a 2 pixel diameter
      x0 = -4, x1 = 4,
      y0 = -4, y1 = 4,
      xsizemode = "pixel",
      ysizemode = "pixel",
      # other visual properties
      fillcolor = "red",
      ## hover info?
      ## stroke??
      line = list(color = "black", stroke = 5)
    )
  )

  # plot the shapes and fitted line
  p <- plot_ly(source = 'mysource', height=200) %>%
    add_lines(x = c(XSTART, input$ld), y = c(1, 1), color = I("black"),
              line = list(widthh=0.5, dash="dot"), showlegend = F) %>%
    add_lines(x = rt_grid()$x, y = rt_grid()$y, color = I("#F89880"),
              showlegend = F,
              hoverinfo = 'y',
              hovertemplate = paste("%{y:.3f}<extra></extra>")
              ) %>% 
    layout(
        plot_bgcolor = '#f0f0f0', # Light grey background
        # xaxis
        xaxis = list(
          title = "Day",
          zerolinecolor = "#f0f0f0", # Light grey zeroline color
          gridcolor = "#ffffff",     # White grid lines
          titlefont = list(family = "Arial, sans-serif"),
          tickfont = list(family = "Arial, sans-serif"),
          range = c(0.1, input$ld + 1)
          #tickvals = c(2),            # Custom tick at x = 2
          #ticktext = c("t=2")       # Custom label for x = 2
        ),
        # yaxis
        yaxis = list(
          title = "R(t)",
          range = c(0, YMAX),
          zerolinecolor = "#f0f0f0", # Light grey zeroline color
          gridcolor = "#ffffff",     # White grid lines
          titlefont = list(family = "Arial, sans-serif"),
          tickfont = list(family = "Arial, sans-serif")
        ),
        margin = list(l = 35, r = 0, b = 0, t = 0), # Adjusted margins
        shapes = circles,
        font = list(family = "Arial, sans-serif")
      ) %>%
      config(edits = list(shapePosition = TRUE)) 
    
    p
})

observe({
    warning("\n************\nCWM Note on 9.24.2024: I haven't figured out how to fix the `plotly` event register warning, it happens when it tries to register the `event_data()` before the plot has data. See this link: https://github.com/plotly/plotly.R/issues/1528\n************\n")
})

# update x/y reactive values in response to changes in shape anchors
observe({
  ed <- event_data("plotly_relayout", source = 'mysource')
  
  shape_anchors <- ed[grepl("^shapes.*anchor$", names(ed))]
  if (length(shape_anchors) != 2) {
    return()
  }
  row_index <- unique(readr::parse_number(names(shape_anchors)) + 1)
  pts <- as.numeric(shape_anchors)
  
  # some controls on the bounds
  if(row_index == 1) {
    rv$x[row_index] <- XSTART
  } else if (row_index == NPTS) {
    rv$x[row_index] <- input$ld
  } else {
    rv$x[row_index] <- sapply(pts[1], function(x) 
      ifelse(x < XSTART, XSTART, ifelse(x > input$ld, input$ld, x)))
  }
  
  rv$y[row_index] <- sapply(pts[2], function(y) 
    ifelse(y < 0, 0, ifelse(y > YMAX, YMAX, y)))
})

```
</div>

Now, create the all subsequent generations within the modeling window (generation # is indicated by fill color in the graph below, with lighter being later generations. The first generation is outlined in red). The offspring of each generation are based on the $R(t)$ value given by the **generation time** of the previous generation. This means that if you are infected, but then there is a lockdown, the $R(t)$ value that determines how many people you infect will decrease to reflect this change. 

Importantly, you may look at the daily reports and notice that the end of the graph and notice that the daily reports trail off as you approach "present day". This is a phenomena known as **right-truncation**, and is due to the reporting delay distribution. At any point in time, due to the administrative delay in reporting, not all recent reports have been entered into the database. After sufficient time has passed these reports will come in but at the present time there is always a lag. The purple line represents reports that will eventually be captured. 

```{r echo=FALSE}
dat_all <- reactive({
  
  dat <- as_tibble(plot_dat())
  
  # this is the first generation
  i1 <- dat$i1   # infection date
  o1 <- dat$o1   # onset date
  gi1 <- dat$gi1 # generation interval
  gen_i <- 1

  # GET RT
  rt_y = rt_grid()$y
  rt_x = rt_grid()$x
  stopifnot(rt_x[1] == 1)
  stopifnot(rt_x[input$ld] == input$ld)
  # print(rt_grid()$x)
  # print(rt_y)
  
  # ----------
  # while there are any initial infection dates lower than the modeling window
  # end, simulate the next generation
  # while (gen_i < 2) {
  while(any(i1<=input$ld)) {
  
    ## new generation
    # print('************')
    gen_i <- gen_i + 1

    ## Infection or Onset dates of previous generation
    inf_date <- as.numeric(names(table(i1)))
    ons_date <- as.numeric(names(table(o1)))
    gi_date  <- as.numeric(names(table(gi1)))
    # print("infection date")
    # print(inf_date)
    # print("onset date")
    # print(ons_date)
    # print("si_date")
    # print(si_date)
    ### IF THERE IS A 0 you're screwed
    if(0 %in% gi_date) stop("0 in gi_date dates")

    ## Number of cases on each infection or onset date
    inf_no   <- as.numeric(table(i1))
    ons_no   <- as.numeric(table(o1))
    gi_no    <- as.numeric(table(gi1))
    stopifnot(sum(inf_no) == sum(ons_no))
    stopifnot(sum(inf_no) == sum(gi_no))
    # print("infection number")
    # print(inf_no)
    # print("onset number")
    # print(ons_no)
    # print("si number")
    # print(si_no)
    ## get the next iteration of rT using the file provided.
    ## repeat RTINF until the end of the sequence,
    ## in this case, the largest onset date
    MAX_DT = 100
    rt <- c(rt_y, rep(RTINF, times = max(MAX_DT))) 
    stopifnot(length(rt[gi_date]) == length(gi_no))
    
    ## then, get a vector of poisson variaables for the 
    ## mu of poisson offspring for the next generation
    ## rt_vec is for the specific dates identified in `date`
    ## if you want this to be based on onset you change this to onset_no
    ## so the onset_dates reflect the transmission and incubation from the previous generation
    ## aka the serial interval
    ## NOW HERE IS THE REAL REAL QUESTION, SHOULD THE RT BE BASED ON THE DATE OF
    ## INFECTION OR THE DATE OF GENERATION
    ## PROBABLY THE DATE OF GENERATION BUT A GOOD QUESTION
    mu   <- gi_no * rt[gi_date]
    # print('mu poisson')
    # print(mu)
    
    # so this gives the expected value of NEW CASES ON SPECIFIC DAYS GIVEN 
    # the current pool of infectees (ons_no) on those days (ons_date)
    
    ## simulate the next generation of infectees
    ## so on the date of symptom onset for current infectees
    # this is the number of people that will be infected
    if(input$GenType == 'Poisson') {
      n1   <- sapply(mu, function(mx) rpois(1, mx))
    } else if(input$GenType == 'NegBinom') {
      n1   <- sapply(mu, function(mx) rnbinom(1, mu = mx, size = input$NB_off))
    } else {
      stop()
    }
    # print('next gen')
    # print(n1)
    # print(sum(n1))
    
    ## *********
    ## ADD A STOPPING CONDITION
    if(sum(n1) > 10000) {
      stop('Next generation of offspring > 10,000. Try changing the shape of R(t)')
    }
    ##
    ## *********

    ## and their infection dates, determined by the onset in i + transmission time
    # include the start dates before the generation time
    # if you change to infection date, you have include the onset time 
    # from the previous generation, because you don't get infected until onset
    
    # Update, no, this is actually determined from the GI of the previous generation
    next_gen_i_days <- do.call(c, lapply(1:length(n1), function(i) {
      rep(gi_date[i], times = n1[i]) }))
    # print(next_gen_i_days)

    # trans1 <- sample(0:input$maxtrans, 
    #                     size = sum(n1), 
    #                     prob = dnbinom(0:input$maxtrans, 
    #                                    size = 1*10^input$trans_i_size, 
    #                                    mu = input$trans_i_mean), 
    #                     replace = TRUE) + TRANS_MIN
    # 
    # stopifnot(length(onset_days) == length(trans1))
    
    i1   <- next_gen_i_days
    
    ## and thier onset times, which is infection + incubation
    inc1 <- sample(0:input$maxinc, 
                          size = sum(n1), 
                          prob = dnbinom(0:input$maxinc, 
                                         size = 1*10^input$inc_i_size, 
                                         mu = input$inc_i_mean), 
                          replace = TRUE) + INC_MIN
      
    o1   <- i1 + inc1
    
    ## and then just tack on the Date of report
    d1   <- o1 + sample(0:input$maxdelay, 
                          size = sum(n1), 
                          prob = dnbinom(0:input$maxdelay, 
                                         size = 1*10^input$NB_r, 
                                         mu = input$NB_m), 
                          replace = TRUE)
    
    ## And now the generation interval for every subsequent generation produced by 
    ## this set of infectors
    ## this is o1 + a new transmission draw
    gi1 <- data.frame(x1 = o1,
             x2 = sample(0:input$maxtrans, 
                        size = sum(n1), 
                        prob = dnbinom(0:input$maxtrans, 
                                       size = 1*10^input$trans_i_size, 
                                       mu = input$trans_i_mean), 
                        replace = TRUE) + TRANS_MIN) %>% mutate(x = x1 + x2)
    gi1 <- unname(gi1$x)
    
    ##
    gen_i_c <- rep(gen_i, length(i1))
    
    dat1 <- cbind(i1, o1, d1, gi1, gen_i_c)
    ###
    dat  <- rbind(dat, dat1)
  }

  dat
  
})

# get aggregated data
# NAs have to be preserved or else
aggDat <- reactive({
  
  x <- as_tibble(dat_all())
  
  max_dt <- max(x$d1)
  
  x1 <- x %>%
    select(-gi1) %>% ## remove g1
    rename("daily_infections" = i1, 
           "daily_onsets" = o1, 
           "daily_reports" = d1) %>%
    pivot_longer(cols = c("daily_infections", "daily_onsets", 
                          "daily_reports")) %>%
    group_by(name, value) %>% tally() %>% 
      rename(day = value) %>%
      pivot_wider(id_cols = day, names_from = name,
                  values_from = n, values_fill = NA) ## MUST BE NA
  
  all_dt <- data.frame(day = 0:max_dt)
  
  x2 <- all_dt %>% left_join(x1, by = join_by(day))
  
  for(j in 2:ncol(x2)) x2[which(is.na(x2[, j])), j] <- NA ## MUST BE NA
  
  x2 %>% filter(day <= input$ld)
  
})


# get all Rt values
allRt <- reactive({
  # print("***")
  rt_y = rt_grid()$y
  rinf = RTINF

  max_dt = max(dat_all()$i1)

  Rall = data.frame(x = 1:max_dt, y = NA)
  for(i in 1:nrow(Rall)) {
    if(i <= input$ld) {
      Rall$y[i] = rt_y[i]
    } else {
      Rall$y[i] = rinf
    }
  }
  
  # print(Rall)
  # print("***2")
  Rall %>% filter(x <= input$ld)
  
})

renderPlot({
  
  # do I want to add in the reporting delay distribution here?
  df <- dat_all()
  # print(head(df))
  
 # now add in right truncation
 reporting_pmf <- as_tibble(reporting_dist()) %>% rename(Day = x,Px = n)
 # print(reporting_pmf)
  
 Px <- rev(cumsum(reporting_pmf$Px))
 nPx = length(Px)
 Ind = (input$ld - nPx + 1):input$ld
 
 rows_to_remove <- c()
 
 for(i in 1:nPx) {
   if(round(Px[i],6) == 1) next(i)
   # first get all the 
   all_indices <- which(df$d1 == Ind[i])
   
   # select which to keep based on bernoulli
   if(length(all_indices) > 0) {
     x <- rbinom(length(all_indices), 1, 1 - Px[i])
     to_remove <- which(x == 1)
     if(any(is.na(x))) {
       print(i)
       stop()
     }
     
     if(length(to_remove) > 0 ) {
       rows_to_remove <- c(rows_to_remove, all_indices[to_remove])
     }
   }
 }
 
 # print("this")
 # print(rows_to_remove)
 
 df <- df[-rows_to_remove, ]
 
 # print(Px)
 
 df2 <-   as_tibble(df) %>%
  select(-gi1) %>% ## remove g1
  rename("Daily Infections" = i1, 
         "Daily Onsets" = o1, 
         "Daily Reports" = d1) %>%
  pivot_longer(cols = c("Daily Infections", "Daily Onsets", 
                        "Daily Reports")) %>%
  filter(!(value > input$ld))
 
 # 
  # get data first
  true_reports <- as_tibble(dat_all()) %>%
    select(-gi1) %>% ## remove g1
    rename("Daily Infections" = i1, 
           "Daily Onsets" = o1, 
           "Daily Reports" = d1) %>%
    pivot_longer(cols = c("Daily Infections", "Daily Onsets", 
                          "Daily Reports")) %>%
    group_by(name, value) %>% tally() %>%
    filter(name == 'Daily Reports') %>%
    filter(value <= input$ld,
           value >= (input$ld - nPx + 1))

  ## summary plot
  # Curves
  df2 %>%
    group_by(name, gen_i_c, value) %>% tally() %>%
    mutate(is_gen_1 = gen_i_c == 1) %>%
    ggplot(.) +
    #
    geom_path(data = true_reports, 
              mapping = aes(x = value, y = n), 
              color = 'purple', linewidth = 1) +
    #
    geom_bar(aes(x = value, fill = gen_i_c, y = n,
                 color = is_gen_1, lwd = is_gen_1),
             position = 'stack', stat = 'identity', width = 1) +
    # geom_path(aes(x = value, y = n), stat = 'identity', fill = '#FF6666', alpha = 0.2) +
    facet_wrap(~name, nrow = 1) + 
    ylab('N') + xlab('Day') +
    scale_fill_continuous(name = 'Gen. #') +
    scale_color_manual(name = "", values = c("transparent", "red")) +
    scale_linewidth_manual(name = "", values = c(0, 1)) +
    # scale_fill_brewer(name = 'Gen.#', type = 'seq', 
    #                   direction = -1, palette = 3) + 
    theme_gray() + 
    coord_cartesian(xlim = c(0, input$ld)) +
    theme(legend.position = 'none',
                axis.text = element_text(size = 10),
          axis.title = element_text(size = 14),
          strip.text = element_text(size = 14))
  
}, height = 200 )
```

Here is another way to visualize right truncation: you can change the present day and view the reports that will have come in on that day as a function of the reporting delay. The red line represents the reports that are actually captured as a function of time, and the grey line represents reports that will eventually be captured. 

```{r, echo = FALSE}

inputPanel(

  renderUI({
      sliderInput('vintage_limit', 'Present day:', min = 10, max = input$ld, step = 1,
              value = 15)
    
  })
  
)

get_vintage_data <- function(data_x, vintage_limit) {
  
    data_x_true <- data_x %>% filter(value <= vintage_limit)
    data_x_vintage <- data_x %>% filter(value <= vintage_limit)
  
      # first, remove anything after vintage day
    data_x_true <- data_x %>% filter(value <= vintage_limit)
    data_x_vintage <- data_x %>% filter(value <= vintage_limit)
    data_x_vintage$Px <- 1
    n_days <- nrow(data_x_vintage)
    
    # now, just for the reports
    reporting_pmf <- as_tibble(reporting_dist()) %>% rename(Day = x,Px = n)
    # print(reporting_pmf)
    
    Px <- rev(cumsum(reporting_pmf$Px))
    # print(Px)
    len_px <- length(Px)
    
    data_x_vintage$Px[(n_days - len_px + 1):n_days] <- Px

    
    # so the simplest version is just to take the fraction, so lets start with that
    data_x_vintage$n_vintage = data_x_vintage$n * data_x_vintage$Px
    data_x_vintage$vintage_limit = vintage_limit
    # i suppose you could sample as well, but this probably does it well enough
    return(data_x_vintage)
}

renderPlot({
    
    if(is.null(input$vintage_limit)) return()
  
    # get data first
    data_x <- as_tibble(dat_all()) %>%
      select(-gi1) %>% ## remove g1
      rename("Daily Infections" = i1, 
             "Daily Onsets" = o1, 
             "Daily Reports" = d1) %>%
      pivot_longer(cols = c("Daily Infections", "Daily Onsets", 
                            "Daily Reports")) %>%
      group_by(name, value) %>% tally() %>%
      filter(name == 'Daily Reports')

    # first, remove anything after vintage day
    data_x_vintage <- get_vintage_data(data_x, vintage_limit = input$vintage_limit)
    
    # plot
    data_x %>% 
      ggplot(.) +
      geom_path(aes(x = value, y = n), color = 'grey') +
      geom_path(data = data_x_vintage,
                mapping = aes(x = value, y = n_vintage), color = 'red', size = 2) +
      facet_wrap(~vintage_limit, nrow = 1) + 
      ylab('N') + xlab('Day') +
      scale_fill_continuous(name = 'Gen. #') +
      scale_color_manual(name = "", values = c("transparent", "red")) +
      scale_linewidth_manual(name = "", values = c(0, 1)) +
      geom_vline(xintercept = input$vintage_limit, color = 'purple', 
                 linetype = '22')+
      theme_gray() + 
      coord_cartesian(xlim = c(0, input$ld)) +
      theme(legend.position = 'none',
                  axis.text = element_text(size = 10),
            axis.title = element_text(size = 14),
            strip.text = element_text(size = 14))
  
}, height = 200, width = 250)

```

# Final thoughts

This document summarizes the various steps occurring in an infectious disease outbreak. Each of the various steps can be modeled differently. Download data below to try for yourself! 

<div style="border: 2px dotted black; border-radius: 15px;padding: 5px; background-color: lightyellow;">
<h3 style="margin-top: 5px; font-size: 1.25em;">Next steps</h3>

Each different components of disease outbreak that can be modeled differently: see our [Decision tool](https://chadmilando.com/RtEstimBook/decisiontree.html) for how to choose software for different analytical goals.
</div>

### Download data

Finally, you can now download **line-list** data for every person within the modeling window, or **aggregated** infections, onsets, and reports by day. The aggregated data has right-truncation built in, while the line list data do not. \

```{r, echo = FALSE}
inputPanel(
  downloadButton("downloadData", "LineList data"),
  downloadButton("downloadAggData", "Aggregated data"),
)

output$downloadData <- downloadHandler(
    filename = function() {
        paste("linelist_data", Sys.Date(), ".csv", sep = "")
    },
    
    content = function(file) {
        write.csv(  as_tibble(dat_all()) %>%
                      filter(i1 <= input$ld) %>%
    rename("day_of_infection" = i1, 
           "day_of_onset" = o1, 
           "day_of_report" = d1) %>%
      select(-gen_i_c) %>%
      mutate(person_id = row_number()) %>%
      select(person_id, day_of_infection,
             day_of_onset, day_of_report), file, row.names = F)
    }
)

output$downloadAggData <- downloadHandler(
    filename = function() {
        paste("aggregated_data", Sys.Date(), ".csv", sep = "")
    },
    
    content = function(file) {
      
      # do I want to add in the reporting delay distribution here?
      df <- dat_all()
      # print(head(df))
      
     # now add in right truncation
     reporting_pmf <- as_tibble(reporting_dist()) %>% 
       rename(Day = x,Px = n)
     # print(reporting_pmf)
      
     Px <- rev(cumsum(reporting_pmf$Px))
     nPx = length(Px)
     Ind = (input$ld - nPx + 1):input$ld
     
     rows_to_remove <- c()
     
     for(i in 1:nPx) {
       # first get all the 
       all_indices <- which(df$d1 == Ind[i])
       
       # select which to keep based on bernoulli
       to_remove <- which(rbinom(length(all_indices), 1, 
                                 1 - Px[i]) == 1)
       
       if(length(to_remove) > 0 ) {
         rows_to_remove <- c(rows_to_remove, all_indices[to_remove])
       }
     }
     
     # print("this")
     # print(rows_to_remove)
     
     df <- df[-rows_to_remove, ]
     
     # print(Px)
     
     df2 <-   as_tibble(df) %>%
      select(-gi1) %>% ## remove g1
      rename("Daily Infections" = i1, 
             "Daily Onsets" = o1, 
             "Daily Reports" = d1) %>%
      pivot_longer(cols = c("Daily Infections", "Daily Onsets", 
                            "Daily Reports")) %>%
      filter(!(value > input$ld))
      
     
        df3 <- df2 %>%
    group_by(name, gen_i_c, value) %>% tally() %>%
    mutate(is_gen_1 = gen_i_c == 1)
      
        write.csv(df3, file, row.names = F)
    }
)

```

<br />
You can also download distributions data. 

```{r, echo = FALSE}
inputPanel(
    downloadButton("dist_serial", "Serial interval"),
    downloadButton("dist_gen", "Generation time"),
    downloadButton("dist_inc", "Incubation time "),
    br(), br(), br(),
    downloadButton("dist_trans", "Transmission time"),
    downloadButton("reporting_dist", "Reporting delay"),
    downloadButton("dist_rt", "Rt")
)

##
output$dist_serial <- downloadHandler(
    filename = function() {
        paste("dist_serial", Sys.Date(), ".csv", sep = "")
    },
    
    content = function(file) {
        write.csv(as_tibble(serial_data()) %>%
                    rename(Day = x,
                           "PMF" = n), file, row.names = F)
    }
)

##
output$dist_gen <- downloadHandler(
    filename = function() {
        paste("dist_gen", Sys.Date(), ".csv", sep = "")
    },
    
    content = function(file) {
        write.csv(as_tibble(gen_data())%>%
                    rename(Day = x,
                           "PMF" = n), file, row.names = F)
    }
)

##
output$dist_inc <- downloadHandler(
    filename = function() {
        paste("dist_inc", Sys.Date(), ".csv", sep = "")
    },
    
    content = function(file) {
        write.csv(as_tibble(inc_data())%>%
                    rename(Day = x,
                           "PMF" = n), file, row.names = F)
    }
)

output$dist_trans <- downloadHandler(
    filename = function() {
        paste("dist_trans", Sys.Date(), ".csv", sep = "")
    },
    
    content = function(file) {
        write.csv(as_tibble(trans_data())%>%
                    rename(Day = x,
                           "PMF" = n), file, row.names = F)
    }
)

output$reporting_dist <- downloadHandler(
    filename = function() {
        paste("reporting_dist", Sys.Date(), ".csv", sep = "")
    },
    
    content = function(file) {
        write.csv(as_tibble(reporting_dist())%>%
                    rename(Day = x,
                           "PMF" = n), file, row.names = F)
    }
)

output$dist_rt <- downloadHandler(
    filename = function() {
        paste("dist_rt", Sys.Date(), ".csv", sep = "")
    },
    
    content = function(file) {
        write.csv(as_tibble(allRt() %>% rename(Day = x,
                           "Rt" = y) %>%
                             left_join(calc_rt() %>%
                                         rename(Day = x, 'Rt_calc' = rt))), file, row.names = F)
    }
)

```

#### Acknowledgements

This page was developed in preparation for the InsightNet Collabathon, Sept 24-26 in Boston, MA, USA. We would like to acknowledge the funding from EpiStorm (CDC NU38FT000013), as well as contributions of code and thoughts from Tenglong Li, PhD^[Boston University, School of Public Health, Department of Biostatistics], Zhenwei Zhou, PhD^[Boston University, School of Public Health, Department of Biostatistics], Christine Sangphet, BA^[Boston University], and Anne Cori, PhD^[Imperial College, London]. The code for this page is available on [Github](https://github.com/cmilando/RtEval).
